---
title: "[AI] AI 모델 성능 평가와 단계별 간략 설명"
excerpt: AI Model Performance Evaluation

categories:
  - AI
tags:
  - [AI, Model, Performance Evaluation]

toc: true
toc_sticky: true
 
date: 2024-03-25
last_modified_at: 2024-03-25
---

## AI 모델 성능 평가란?
---
AI 모델 성능 평가는 개발된 AI 모델이 얼마나 정확하고 효과적으로 예측, 분류, 또는 생성 작업을 수행하는지를 측정하는 과정입니다. <br> 
즉, 모델이 실제 데이터에 대해 얼마나 잘 작동하는지를 평가하는 것입니다.

## 평가의 목적
---
* 모델의 성능 측정: 모델의 정확도, 정밀도, 재현율 등을 측정하여 모델의 성능을 수치적으로 확인합니다.
* 모델 비교: 여러 모델의 성능을 비교하여 가장 적합한 모델을 선택합니다.
* 모델 개선: 모델의 성능이 기대에 미치지 못할 경우, 하이퍼파라미터 조정, 모델 구조 변경 등을 통해 모델을 개선합니다.


## 평가 대상
---
* Accuracy : 모델이 전체 데이터 중 얼마나 정확하게 예측했는지 나타내는 지표입니다.
* Precision : 양성으로 예측한 것 중 실제 양성인 비율입니다.
* Recall : 실제 양성인 것 중 모델이 양성으로 예측한 비율입니다.
* F1 스코어 : 정밀도와 재현율의 조화 평균으로, 두 지표를 동시에 고려한 평가 지표입니다.
* ROC 곡선 : 다양한 임계값에서의 TPR(True Positive Rate)과 FPR(False Positive Rate)의 관계를 나타내는 곡선으로, 모델의 성능을 시각적으로 확인할 수 있습니다.
* Confusion Matrix : 각 클래스에 대한 예측 결과를 표로 나타낸 것으로, 모델의 오류 유형을 분석하는 데 사용됩니다.
* Loss Function : 모델의 예측 값과 실제 값 사이의 차이를 측정하는 함수입니다.
* Mean Squared Error, MSE : 회귀 문제에서 주로 사용되는 손실 함수로, 예측 값과 실제 값의 차이의 제곱의 평균을 나타냅니다.
* Cross-Entropy : 분류 문제에서 주로 사용되는 손실 함수로, 예측 확률 분포와 실제 분포 사이의 차이를 측정합니다.


## 평가 순서 및 단계
---
* 데이터 분할: 학습 데이터, 검증 데이터, 테스트 데이터로 나눕니다.
  * 학습 데이터: 모델을 학습시키는 데 사용됩니다.
  * 검증 데이터: 하이퍼파라미터를 조정하고 모델을 선택하는 데 사용됩니다.
  * 테스트 데이터: 최종적으로 모델의 성능을 평가하는 데 사용됩니다.


* 모델 학습: 학습 데이터를 이용하여 모델을 학습시킵니다.
* 모델 평가: 검증 데이터를 이용하여 모델의 성능을 평가하고, 필요에 따라 하이퍼파라미터를 조정하거나 모델 구조를 변경합니다.
* 최종 평가: 테스트 데이터를 이용하여 최종적으로 모델의 성능을 평가합니다.


## 각 단계별 중요 포인트 및 주의 사항
---
* 데이터 분할
  * 데이터의 분포가 학습 데이터, 검증 데이터, 테스트 데이터에서 비슷해야 합니다. 
  * 데이터 불균형 문제를 해결해야 합니다.

* 모델 학습
  * 적절한 손실 함수와 최적화 알고리즘을 선택해야 합니다.
  * 과적합(Overfitting)과 과소적합(Underfitting)을 방지해야 합니다.
 
* 모델 평가
  * 다양한 평가 지표를 사용하여 모델의 성능을 종합적으로 평가해야 합니다.



<br> 

[Top](#){: .btn .btn--primary }{: .align-right}